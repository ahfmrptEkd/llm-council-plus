# LLM Council Configuration
# Copy this file to .env and fill in your values
#
# QUICK START (minimal config for local development):
#   1. Copy this file to .env
#   2. Set ROUTER_TYPE=litellm (for local models and cloud models) OR set OPENROUTER_API_KEY
#   3. Run: docker compose up --build
#
# For production deployment, see SECURITY.md

# =============================================================================
# AUTHENTICATION (disabled by default for easy open source setup)
# =============================================================================

# Enable/disable authentication (default: false)
# When false, all users are treated as "guest"
AUTH_ENABLED=false

# Secret key for JWT token signing (REQUIRED when AUTH_ENABLED=true)
# Generate with: openssl rand -base64 32
JWT_SECRET=

# User credentials (JSON format, REQUIRED when AUTH_ENABLED=true)
# Format: {"username": "password", ...}
# Passwords are hashed with bcrypt at startup
AUTH_USERS={}

# =============================================================================
# LLM ROUTER CONFIGURATION
# =============================================================================

# Router type: 'openrouter' or 'litellm'
ROUTER_TYPE=openrouter

# OpenRouter settings (required if ROUTER_TYPE=openrouter)
# Leave empty to use the Setup Wizard
OPENROUTER_API_KEY=
OPENROUTER_API_URL=https://openrouter.ai/api/v1/chat/completions

# Ollama settings (used if ROUTER_TYPE=ollama)
# If backend runs in Docker and Ollama runs on your host, use: host.docker.internal:11434
# ollama is integrated in LiteLLM "USE_OLLAMA_MODELS" will use local models

OLLAMA_HOST=localhost:11434
USE_OLLAMA_MODELS=true

# liteLLM cloude model api and endpoints

## AZURE
AZURE_PROJECT_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_PROJECT_ANTHROPIC_ENDPOINT=https://your-resource.anthropic.azure.com/
AZURE_PROJECT_EXTRA_ENDPOINT=https://your-extra-resource.openai.azure.com/
AZURE_API_KEY=your-azure-api-key

## Google
GEMINI_AI_API_KEY=your-gemini-api-key

## Grok (xAI) - LiteLLM uses XAI_API_KEY
GROK_API_KEY=your-grok-api-key

# =============================================================================
# LLM MONITORING CONFIGURATION
# =============================================================================

# if you are not using it comments. Else it will trigger error.
# LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
# LANGFUSE_SECRET_KEY=your-langfuse-secret-key
# LANGFUSE_HOST=http://localhost:3000  # 기본값, 선택사항

# =============================================================================
# MODEL CONFIGURATION (Optional - models are selected via Setup Wizard)
# =============================================================================

# Maximum number of council models allowed (default: 5)
MAX_COUNCIL_MODELS=5

# Browse all available models at https://openrouter.ai/models

# =============================================================================
# TIMEOUT SETTINGS
# =============================================================================

# Default timeout for API requests (seconds)
DEFAULT_TIMEOUT=120.0

# Timeout for title generation (seconds)
TITLE_GENERATION_TIMEOUT=180.0

# =============================================================================
# WEB SEARCH (TAVILY)
# =============================================================================

# Enable Tavily web search integration
ENABLE_TAVILY=false

# Tavily API key (get from https://tavily.com)
TAVILY_API_KEY=

# =============================================================================
# WEB SEARCH (EXA) - Alternative to Tavily
# =============================================================================

# Enable Exa AI-powered web search integration
ENABLE_EXA=false

# Exa API key (get from https://exa.ai)
EXA_API_KEY=

# =============================================================================
# GOOGLE DRIVE INTEGRATION (OPTIONAL)
# =============================================================================

# Google Drive folder ID for auto-upload
# Leave empty to disable Google Drive integration
GOOGLE_DRIVE_FOLDER_ID=

# Path to Google service account credentials file
# GOOGLE_SERVICE_ACCOUNT_FILE=/app/credentials/google-service-account.json

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

# Backend API URL for frontend (used during Docker build)
# Ngnix will automatic proxy to backend leave a blank
VITE_API_BASE=